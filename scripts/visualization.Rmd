---
title: "Visualization"
author: "DeepGP Project"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

In this notebook we build and compare several Gaussian-process–based models on the 2-D **Branin** benchmark function. The aim is to demonstrate how deeper GP architectures (two- and three-layer) **warp** the input space, leading to improved predictive accuracy and calibrated uncertainty.

The first half of the document prepares data, fits the models, and summarises scalar performance metrics. Subsequent sections will visualise the learned transformations and compare model behaviour.

## Experimental Setup

In this section we load the required R packages for modelling (`deepgp`), experimental design (`lhs`), and visualisation (`ggplot2`, `gridExtra`, `hexbin`).  All helper functions in the `R/` directory are sourced so that the notebook always uses the project’s current implementation.

```{r load-libraries, warning = FALSE, message = FALSE}
# ── Load core modelling and visualisation packages ──
library(deepgp)   # Deep Gaussian Process fitting routines
library(lhs)      # Latin Hypercube Sampling for design generation
library(ggplot2)  # Plotting
library(gridExtra) # Arranging multiple ggplot objects
library(dplyr, quietly = TRUE, warn.conflicts = FALSE)   # Data manipulation helpers
library(hexbin)   # Hex-bin density plots

# Load all project helper scripts so the notebook uses the same codebase
files <- list.files("R", pattern = "\\.R$", full.names = TRUE)
invisible(lapply(files, source))
rm(files)
```

The libraries and helpers are now available; we next generate training and test data.

## Generating Training and Test Data

We create two independent data sets:
1. **Training set** – a small Latin Hypercube Sample (`n_train = 20`) used to fit the models.
2. **Test set** – a denser sample (`n_test = 100`) used purely for out-of-sample evaluation.

The Branin inputs are generated in their natural domain and later internally scaled by helper functions.

```{r generate-data, warning = FALSE, message = FALSE}
# --- Define reproducible experimental parameters ---
set.seed(548)          # Ensure repeatability of the random design

fn_name     <- "branin" # Target test function
dim         <- 2        # Branin is inherently 2-D
n_train     <- 20       # Number of training points
n_test      <- 100      # Number of test points
noise_level <- 0.1      # Gaussian noise standard deviation
n_mcmc      <- 1000     # MCMC iterations for each model
```

```{r generate-data, warning = FALSE, message = FALSE}
# --- Evaluate the Branin function on training and test points ---
# Obtain function handle
test_fn <- get_function(fn_name)

# Generate input designs
x_train <- generate_data(fn_name, n_train, dim)
 x_test <- generate_data(fn_name, n_test,  dim)

# Add observational noise to outputs
y_train <- evaluate_function(x_train, test_fn, noise_level)
y_test  <- evaluate_function(x_test,  test_fn, noise_level)
```

## Fitting Models and Making Predictions

DeepGP provides increasing representational capacity with each additional hidden layer.  We therefore fit three models under identical settings and later compare their behaviour.

### Model 1: Standard Gaussian Process (GP)

The baseline – a single-layer GP with a stationary covariance.  While flexible, it cannot perform non-linear input warping.

```{r gp-model, warning = FALSE, message = FALSE}
# Fit the GP baseline
mod_gp <- fit_model("GP", x_train, y_train, n_mcmc)

# Predict on test points and back-transform to the original scale
pred_mod_gp   <- predict_deepgp(mod_gp, x_test)
y_hat_gp <- pred_mod_gp$y_hat  # Contains mean, lower, upper

# Calculate basic performance metrics
rmse_gp     <- sqrt(mean((y_hat_gp$mean - y_test)^2))
r2_gp       <- 1 - mean((y_hat_gp$mean - y_test)^2) / var(y_test)
coverage_gp <- mean(y_test >= y_hat_gp$lower & y_test <= y_hat_gp$upper) * 100
```

### Model 2: Two-Layer Deep Gaussian Process (DGP2)

Adds one hidden layer, enabling the model to learn a non-linear mapping (warping) of the input space before applying a GP at the output layer.

```{r dgp2-model, warning = FALSE, message = FALSE}
mod_dgp2 <- fit_model("DGP2", x_train, y_train, n_mcmc)
pred_mod_dgp2 <- predict_deepgp(mod_dgp2, x_test)
y_hat_dgp2 <- pred_mod_dgp2$y_hat

rmse_dgp2     <- sqrt(mean((y_hat_dgp2$mean - y_test)^2))
r2_dgp2       <- 1 - mean((y_hat_dgp2$mean - y_test)^2) / var(y_test)
coverage_dgp2 <- mean(y_test >= y_hat_dgp2$lower & y_test <= y_hat_dgp2$upper) * 100
```

### Model 3: Three-Layer Deep Gaussian Process (DGP3)

Introduces a second hidden layer for even richer transformations.  We include it to test whether additional depth yields measurable gains on this moderately complex function.

```{r dgp3-model, warning = FALSE, message = FALSE}
mod_dgp3 <- fit_model("DGP3", x_train, y_train, n_mcmc)
pred_mod_dgp3 <- predict_deepgp(mod_dgp3, x_test)
y_hat_dgp3 <- pred_mod_dgp3$y_hat

rmse_dgp3     <- sqrt(mean((y_hat_dgp3$mean - y_test)^2))
r2_dgp3       <- 1 - mean((y_hat_dgp3$mean - y_test)^2) / var(y_test)
coverage_dgp3 <- mean(y_test >= y_hat_dgp3$lower & y_test <= y_hat_dgp3$upper) * 100
```

## Results Comparison

The table below summarises **root-mean-square error (RMSE)**, **coefficient of determination (R²)**, and empirical **95 % coverage** of the predictive intervals for each model.

```{r results-comparison}
# Collect metrics in a tidy data frame
results <- data.frame(
  model_variant = c("GP", "DGP2", "DGP3"),
  rmse     = c(rmse_gp,  rmse_dgp2,  rmse_dgp3),
  coverage = c(coverage_gp, coverage_dgp2, coverage_dgp3),
  r2       = c(r2_gp,  r2_dgp2,  r2_dgp3)
)

# Render as an HTML table
knitr::kable(
  results,
  caption = "Performance comparison on the Branin test function",
  digits = c(0, 4, 2, 2)
)
```

## Visualization

### 1. Model Predictions vs Actual Values

*What are we doing?* We visualise each model’s predicted mean against the true Branin responses on the test set. Every point represents one test location for a given model.

*Why are we doing it?* Numeric summaries such as RMSE hide where and how the model makes errors. A scatter-plot reveals systematic bias (points consistently above/below the diagonal) and variance patterns that guide further model improvements.

*How are we doing it?* A tidy long-format data frame is created, then `ggplot2` draws a coloured scatter for the three model variants. The 45-degree dashed line marks perfect predictions. We lock the axis scale with `coord_fixed` and `aspect.ratio = 1` so visual distance from the line directly reflects prediction error.

```{r basic-visualization, warning = FALSE, message = FALSE, fig.width = 5, fig.height = 5}
# ── Assemble tidy data for plotting ──
plot_data <- data.frame(
  index = rep(seq_len(n_test), 3),                # Identifier (not plotted)
  model_variant = factor(rep(c("GP", "DGP2", "DGP3"), each = n_test),
                         levels = c("GP", "DGP2", "DGP3")),
  actual    = rep(y_test, 3),                     # Ground-truth responses
  predicted = c(y_hat_gp$mean,                    # Concatenate model predictions
                 y_hat_dgp2$mean,
                 y_hat_dgp3$mean)
)

# ── Draw scatter with identity reference ──
ggplot(plot_data, aes(x = actual, y = predicted,
                      colour = model_variant, shape = model_variant)) +
  geom_point(size = 1.2, alpha = 0.7) +                       # semi-transparent markers
  geom_abline(slope = 1, intercept = 0,                       # y = x reference
              linetype = "dashed", colour = "grey50") +
  coord_fixed(ratio = 1) +                                    # equal scale on both axes
  scale_color_brewer(palette = "Set1") +                     # distinct colours
  theme_minimal() +
  theme(legend.position = "bottom",
        aspect.ratio = 1) +                                   # square plotting panel
  labs(title = "Predicted vs Actual Values",
       subtitle = "Points closer to the dashed line indicate better predictions",
       x = "Actual Branin value",
       y = "Predicted mean",
       colour = "Model",
       shape  = "Model")
```

### 2. Prediction Intervals Visualization

*What are we doing?* Here we inspect the **95 % predictive intervals** delivered by each model alongside the point predictions and true responses.

*Why are we doing it?*  A model should not only give accurate means but also **well-calibrated uncertainty**—narrow where the function is easy, wider where it is hard.  Visualising intervals for a small subset of test points lets us gauge whether the empirical coverage (from the results table) matches the eye test.

*How are we doing it?* We select the first `subset_size` test points (for clarity) and build a long data frame with lower/upper bounds.  `ggplot2` then draws error bars (intervals), coloured points (means) and black crosses (truth).  Faceting by model provides side-by-side comparison while keeping a common y-scale.

```{r prediction-intervals, fig.height = 4, warning = FALSE, message = FALSE}
# ── Choose a manageable subset for clarity ──
subset_size <- min(15, n_test)                   # up to 15 points
subset_idx  <- seq_len(subset_size)

# ── Assemble tidy data frame ──
intervals_data <- data.frame(
  index = rep(subset_idx, 3),
  model_variant = factor(rep(c("GP", "DGP2", "DGP3"), each = subset_size),
                         levels = c("GP", "DGP2", "DGP3")),
  actual    = rep(y_test[subset_idx], 3),
  predicted = c(y_hat_gp$mean[subset_idx],
                y_hat_dgp2$mean[subset_idx],
                y_hat_dgp3$mean[subset_idx]),
  lower = c(y_hat_gp$lower[subset_idx],
            y_hat_dgp2$lower[subset_idx],
            y_hat_dgp3$lower[subset_idx]),
  upper = c(y_hat_gp$upper[subset_idx],
            y_hat_dgp2$upper[subset_idx],
            y_hat_dgp3$upper[subset_idx])
)

# ── Plot intervals and truth ──
ggplot(intervals_data, aes(x = factor(index), y = predicted, colour = model_variant)) +
  geom_point(size = 2) +                                      # predicted mean
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.3) +
  geom_point(aes(y = actual), shape = 4, size = 2.5, colour = "black") +  # truth as ×
  facet_wrap(~ model_variant, ncol = 1) +                     # one column layout
  labs(title = "Prediction Intervals vs Actual Values",
       subtitle = "Black cross = true value; coloured dot = mean; bar = 95 % interval",
       x = "Test point index",
       y = "Branin value") +
  theme_minimal() +
  theme(legend.position = "none")
```

### 3. Grid Warping Visualization
*What are we doing?* We start with a regular lattice in the **original input space** and pass those points through the first hidden layer of the two-layer DGP. By connecting neighbouring lattice points before and after transformation we can **see** how the model warps distances and angles.

*Why are we doing it?* The core advantage of a deep GP is its learned non-linear *input warping*.  This plot provides an intuitive picture of that warp, complementing numeric metrics.  Ideally the hidden layer will stretch regions where the function varies quickly and compress regions of low variation.

*How are we doing it?* 
1. Create a 10×10 grid on `[0,1]²` (the domain used throughout the notebook).
2. Predict with `mod_dgp2` while requesting latent variables.
3. Average over *M* MCMC draws (`n_mcmc`) to obtain the mean hidden-layer location per input.
4. Bind the original and transformed coordinates, then draw **blue** row connections and **red** column connections in separate facets.

```{r grid-warping-advanced, fig.width = 9, fig.height = 4.5, warning = FALSE, message = FALSE}
# ── 1. Construct regular input grid ──
grid_size  <- 50
x1_seq     <- seq(0, 1, length.out = grid_size)
x2_seq     <- seq(0, 1, length.out = grid_size)
grid_points <- expand.grid(x1 = x1_seq, x2 = x2_seq)
grid_matrix <- as.matrix(grid_points)

# ── 2. Predict latent representation from DGP2 ──
grid_pred2 <- predict(
  mod_dgp2,
  x_new        = grid_matrix,
  lite         = TRUE,
  return_all   = TRUE,
  store_latent = TRUE
)

# ── 3. Average latent variable draws ──
grid_hidden2 <- Reduce("+", grid_pred2$w_new) / n_mcmc   # n_mcmc defined earlier

# ── 4. Prepare tidy data for plotting ──
# Label grid indices so we can join neighbouring points later
grid_points$row_id <- rep(seq_len(grid_size), each = grid_size)   # constant along rows
grid_points$col_id <- rep(seq_len(grid_size), times = grid_size)  # constant along columns

input_df  <- cbind(grid_points[, c("x1", "x2")],
                   row_id = grid_points$row_id,
                   col_id = grid_points$col_id,
                   y = grid_pred2$mean,
                   space  = "Input Space")

hidden_df <- data.frame(x1 = grid_hidden2[, 1],
                        x2 = grid_hidden2[, 2],
                        row_id = grid_points$row_id,
                        col_id = grid_points$col_id,    
                        y = grid_pred2$mean,
                        space  = "Hidden Layer")

grid_warping <- rbind(input_df, hidden_df) %>%
  dplyr::mutate(space = factor(space, levels = c("Input Space", "Hidden Layer")))

# ── 5. Draw warp grid ──
ggplot(grid_warping, aes(x = x1, y = x2)) +
  geom_point(size = 0.9, alpha = 0.7) +
  geom_path(aes(group = interaction(space, row_id)), colour = "blue", alpha = 0.4) +
  geom_path(aes(group = interaction(space, col_id)), colour = "red",  alpha = 0.4) +
  facet_wrap(~ space, scales = "free") +
  labs(title = "Grid Warping Effect of the Two-Layer DGP",
       subtitle = "Blue lines follow grid rows, red lines follow columns",
       x = "Dimension 1", y = "Dimension 2") +
  theme_minimal() 
```

### 4. Model Prediction Surface Comparison

**What are we looking at?** This visualization compares the predicted response surfaces from our three GP models (standard GP, two-layer DGP2, three-layer DGP3) against the true Branin function. We display all four surfaces as heat maps with a common color scale to facilitate direct visual comparison.

**Why do we care?** The Branin function has several local minima and curved ridges that are challenging for standard GPs to capture. By comparing the predicted surfaces, we can visually assess how the deeper architectures (DGP2, DGP3) better approximate the true function's complex structure through their non-linear warping of the input space.

**How are we implementing it?** We use the same 50×50 grid from the warping visualization to ensure consistent evaluation points. For each model, we obtain predictions directly from the `predict()` function (which maintains the scaled domain), and then arrange them in a tidy data frame for faceted plotting.

```{r prediction-surface, fig.width=12, fig.height=10}
# ── 1. Obtain predictions from all models on our standard grid ──
# For the standard GP model, get predictions and store latent variables
grid_pred1 <- predict(
  mod_gp,
  x_new        = grid_matrix,
  lite         = TRUE,          # keep full object incl. latent
  return_all   = TRUE,
  store_latent = TRUE
)

# Obtain latent (hidden-layer) representation using deepgp directly
grid_pred3 <- predict(
  mod_dgp3,
  x_new        = grid_matrix,
  lite         = TRUE,          # keep full object incl. latent
  return_all   = TRUE,
  store_latent = TRUE
)

# ── 2. Calculate true Branin function values (in scaled space) ──
# First map grid points back to original domain, then apply Branin function, then scale result
y_grid <- scale_y(y = apply(scale_x(x_scaled = grid_matrix, x_min = mod_gp$x_min, x_max = mod_gp$x_max, reverse = TRUE), 1, branin))$scaled

# ── 3. Assemble tidy data frame for visualization ──
# Combine all four surfaces (actual + 3 models) into a single data frame
surface_comparison <- data.frame(
  x1 = rep(grid_points$x1, 4),
  x2 = rep(grid_points$x2, 4),
  y = c(y_grid, grid_pred1$mean, grid_pred2$mean, grid_pred3$mean),
  model = rep(c("Actual Values" , "Standard GP", "Two-Layer GP", "Three-Layer GP"), each = nrow(grid_matrix))
) %>%
 mutate(model = factor(model, levels = c("Actual Values", "Standard GP", "Two-Layer GP", "Three-Layer GP")))

# ── 4. Create faceted heat map visualization ──
# Plot all surfaces with common viridis color scale for fair comparison
ggplot(surface_comparison, aes(x = x1, y = x2, fill = y)) +
  geom_tile() +
  scale_fill_viridis_c() +
  facet_wrap(~ model, ncol = 2) +
  labs(
    title = "Model Prediction Surface Comparison",
    x = "Input Dimension 1 (Standardized)",
    y = "Input Dimension 2 (Standardized)",
    fill = "Predicted Value"
  ) +
  theme_minimal()
```



### 5. Uncertainty Visualization

**What are we looking at?** This visualization reveals how each model quantifies its predictive uncertainty across the input space. We extract the variance (s2) from each model's predictions and display it as a heat map, with brighter colors indicating higher uncertainty.

**Why do we care?** Well-calibrated uncertainty is crucial for reliable decision-making with surrogate models. Standard GPs tend to have relatively uniform uncertainty patterns, while deeper GPs can adapt their uncertainty estimates to the local complexity of the function - increasing confidence in smooth regions and expressing greater uncertainty in rapidly changing areas.

**How are we implementing it?** We reuse the same grid and model predictions from the previous section, extract the variance (s2) component, and visualize it with a sequential color palette that highlights regions of high uncertainty.

```{r uncertainty-viz, fig.width=12, fig.height=10}
# ── 1. Extract uncertainty (variance) from model predictions ──
# Filter out the 'Actual Values' entry and add uncertainty column from each model's s2 (variance)
uncertainty_comparison <- surface_comparison %>%
  filter(model != "Actual Values") %>%
  mutate(uncertainty = c(grid_pred1$s2, grid_pred2$s2, grid_pred3$s2))

# ── 2. Create heat map visualization of uncertainty across input space ──
# Use 'inferno' palette where brighter colors indicate higher uncertainty
ggplot(uncertainty_comparison, aes(x = x1, y = x2, fill = uncertainty)) +
  geom_tile() +
  scale_fill_viridis_c(option = "inferno") +
  facet_wrap(~ model, ncol = 2) +
  labs(
    title = "Model Uncertainty Comparison",
    subtitle = "Width of 95% prediction intervals",
    x = "Input Dimension 1 (Standardized)",
    y = "Input Dimension 2 (Standardized)",
    fill = "Uncertainty\n(Interval Width)"
  ) +
  theme_minimal()
```

### 6. Density Comparison Visualization

**What are we looking at?**
This visualization compares the density of points in the input space versus the
hidden layer space, showing how the warping effect changes the distribution of
points. Demonstrates how the hidden layer transforms a uniform distribution of
points into a non-uniform distribution, effectively allocating more
representational capacity to regions of the input space that require more
flexibility.

**Why do we care?** 
Understanding how the hidden layer warps the input space helps us appreciate the
non-linear transformations that enable the model to capture complex patterns in
the data.

**How are we implementing it?**

We reuse our existing training data (`x_train`) to maintain consistency across analyses, transform these points through the hidden layer, and then compare the density distribution in both spaces using hexagonal binning.

```{r density-comparison, fig.width=12, fig.height=6}
# ── 2. Transform training points through the DGP2 hidden layer ──
# Average over MCMC samples to get stable hidden layer representations
train_dgp2_hidden <- Reduce(
  "+",
  predict(
    mod_dgp2,
    x_new = grid_matrix,
    lite = TRUE,
    return_all = TRUE,
    store_latent = TRUE
  )$w_new
) / n_mcmc

# ── 3. Assemble tidy data frame for comparison ──
# Combine original and transformed points with space labels for faceting
density_comparison <- data.frame(
  x1 = c(grid_points$x1, train_dgp2_hidden[, 1]),  # First dimension from both spaces
  x2 = c(grid_points$x2, train_dgp2_hidden[, 2]),  # Second dimension from both spaces
  space = rep(c("Input Space", "Hidden Layer Space"), each = nrow(grid_matrix))  # Labels for faceting
)

# ── 4. Visualize density using hexagonal binning ──
# Hexbins show how points cluster differently in each space
ggplot(density_comparison, aes(x = x1, y = x2)) +
  geom_hex(bins = 20) +  # Hexagonal bins count points in each region
  scale_fill_viridis_c(name = "Count") +  # Color by point density
  facet_wrap(~ space, scales = "free") +
  labs(
    title = "Density Transformation in Two-Layer GP",
    subtitle = "Uniform density in input space becomes non-uniform in hidden layer space",
    x = "Dimension 1",
    y = "Dimension 2"
  ) +
  theme_minimal()
```

### 7. K-Means Clustering Visualization

**What are we looking at?** This visualization demonstrates how the hidden layer transforms non-linearly separable classes into more separable ones. We create synthetic class labels based on a sinusoidal decision boundary and observe how these classes are reorganized in the hidden layer space.

**Why do we care?** One of the key benefits of deep models is their ability to transform complex, entangled patterns into more separable representations. This visualization provides intuitive evidence of how the DGP2 model's hidden layer creates a more effective feature space for classification tasks.

**How are we implementing it?** We generate points with synthetic class labels defined by a non-linear function, transform them through the hidden layer, and compare the class distributions in both spaces side by side.

```{r kmeans-visualization, fig.width=12, fig.height=6}
# ── 1. Create synthetic classes with a non-linear decision boundary ──
# Using a sinusoidal function creates classes that aren't linearly separable
class_labels <- ifelse(
  sin(grid_matrix[,1] * 3 * pi) * cos(grid_matrix[,2] * 3 * pi) > 0,
  "Class A", "Class B"
)

# ── 2. Prepare data frames for both spaces ──
# Input space data frame
class_input <- data.frame(
  x1 = grid_matrix[, 1],
  x2 = grid_matrix[, 2],
  class = factor(class_labels)
)

# Hidden layer space data frame (same classes, transformed coordinates)
class_hidden <- data.frame(
  x1 = grid_hidden2[, 1],
  x2 = grid_hidden2[, 2],
  class = factor(class_labels)
)

# ── 5. Create plots for side-by-side comparison ──
# Input space plot
p1 <- ggplot(class_input, aes(x = x1, y = x2, color = class)) +
  geom_point(size = 3, alpha = 0.7) +
  scale_color_manual(values = c("Class A" = "blue", "Class B" = "red")) +
  labs(
    title = "Input Space Classes",
    x = "Input Dimension 1",
    y = "Input Dimension 2"
  ) +
  theme_minimal()

# Hidden layer space plot
p2 <- ggplot(class_hidden, aes(x = x1, y = x2, color = class)) +
  geom_point(size = 3, alpha = 0.7) +
  scale_color_manual(values = c("Class A" = "blue", "Class B" = "red")) +
  labs(
    title = "Hidden Layer Space Classes",
    x = "Hidden Layer Dimension 1",
    y = "Hidden Layer Dimension 2"
  ) +
  theme_minimal()

# ── 6. Arrange plots side by side ──
gridExtra::grid.arrange(p1, p2, ncol = 2,
                       top = "Class Transformation in Two-Layer GP")
```




### 8. Voronoi Tessellation

**What are we looking at?** Voronoi tessellation divides space into regions based on proximity to a set of seed points. This visualization shows how the hidden layer of our DGP2 model transforms these proximity-based regions, revealing how the model warps the notion of "distance" in feature space.

**Why do we care?** Voronoi cells provide an intuitive way to visualize how the hidden layer transforms the metric structure of the input space. This transformation is key to understanding why deeper GPs can better capture complex functions like Branin - they effectively change the distance metric to better match the structure of the target function.

**How are we implementing it?** We generate a small set of random seed points, compute their Voronoi tessellation in both input space and hidden layer space, and display them side by side for comparison.

```{r voronoi-tessellation, fig.width=12, fig.height=8, warning=FALSE, message=FALSE}
# ── 1. Generate seed points for Voronoi tessellation ──
n_seeds <- 15  # Small number for visual clarity
set.seed(123)  # For reproducibility
seed_points <- matrix(runif(n_seeds * 2), ncol = 2)  # Random points in [0,1]²

# ── 2. Transform seed points through the DGP2 hidden layer ──
# Average over MCMC samples for stable hidden layer representations
seed_hidden <- Reduce(
  "+",
  predict(
    mod_dgp2,
    x_new = seed_points,
    lite = TRUE,
    return_all = TRUE,
    store_latent = TRUE
  )$w_new
) / n_mcmc

# ── 3. Create Voronoi tessellation function ──
# This function creates a Voronoi diagram from seed points
create_voronoi <- function(points, title = "Voronoi Tessellation") {
  # Scale points to [0,1] range for consistent visualization
  points_scaled <- points
  if (min(points[,1]) != max(points[,1])) {
    points_scaled[,1] <- (points[,1] - min(points[,1])) / (max(points[,1]) - min(points[,1]))
  }
  if (min(points[,2]) != max(points[,2])) {
    points_scaled[,2] <- (points[,2] - min(points[,2])) / (max(points[,2]) - min(points[,2]))
  }
  
  # Create a dense grid for approximating Voronoi cells
  grid_size <- 100
  x_seq <- seq(0, 1, length.out = grid_size)
  y_seq <- seq(0, 1, length.out = grid_size)
  grid <- expand.grid(x = x_seq, y = y_seq)
  
  # For each grid point, find the nearest seed point
  nearest_seed <- rep(0, nrow(grid))
  for (i in 1:nrow(grid)) {
    min_dist <- Inf
    for (j in 1:nrow(points_scaled)) {
      dist <- sqrt((grid$x[i] - points_scaled[j,1])^2 + (grid$y[i] - points_scaled[j,2])^2)
      if (dist < min_dist) {
        min_dist <- dist
        nearest_seed[i] <- j
      }
    }
  }
  
  # Create data frame for plotting
  plot_data <- data.frame(
    x = grid$x,
    y = grid$y,
    region = factor(nearest_seed)
  )
  
  # Create the plot
  ggplot() +
    geom_tile(data = plot_data, aes(x = x, y = y, fill = region), alpha = 0.7) +
    geom_point(data = data.frame(x = points_scaled[,1], y = points_scaled[,2]), 
               aes(x = x, y = y), color = "red", size = 3) +
    scale_fill_viridis_d() +
    labs(title = title) +
    theme_minimal() +
    theme(legend.position = "none") +
    coord_fixed(ratio = 1)  # Ensure aspect ratio is 1:1
}

# ── 4. Create Voronoi plots for both spaces ──
p1 <- create_voronoi(seed_points, "Input Space Voronoi Tessellation")
p2 <- create_voronoi(seed_hidden, "Hidden Layer Voronoi Tessellation")

# ── 5. Arrange plots side by side ──
gridExtra::grid.arrange(
  p1, p2, 
  ncol = 2,
  top = "Voronoi Tessellation Transformation in Two-Layer GP"
)
```

This visualization reveals how the DGP2 model's hidden layer transforms the notion of proximity in feature space. In the input space (left), each colored region represents points that are closest to a particular seed point (shown in red). After transformation through the hidden layer (right), these regions are warped and reshaped.

The warping effect demonstrates how the model effectively changes the distance metric to better match the structure of the Branin function. Regions that require more modeling flexibility are expanded, while simpler regions are compressed. This adaptive metric is a key advantage of deeper GP architectures over standard GPs, which are constrained to use a stationary covariance function with a fixed notion of distance.

### 9. 3D Surface Visualization

**What are we looking at?** This visualization shows the true Branin function as a 3D surface, with x1 and x2 as inputs and the function value as the height (z-axis). 

**Why do we care?** While 2D heat maps are useful, 3D surfaces provide a more intuitive understanding of the function's shape, including its peaks, valleys, and gradients. This helps us appreciate the complexity of the Branin function that our models are trying to approximate.

**How are we implementing it?** We use the `plotly` package to create an interactive 3D surface plot. We evaluate the Branin function on a regular grid in its natural domain (x₁ ∈ [-5,10], x₂ ∈ [0,15]) to show its true shape.

```{r 3d-surface, fig.width=8, fig.height=6, warning=FALSE, message=FALSE}
# ── 1. Load required libraries ──
library(plotly)

# ── 2. Prepare data for 3D visualization ──
# For plotly surface plots, we need to reshape the data into a matrix
# Extract unique x1 and x2 values (assuming they form a grid)
x1_unique <- sort(unique(input_df$x1))
x2_unique <- sort(unique(input_df$x2))

# Create a matrix for the z values
z_matrix <- matrix(NA, nrow = length(x1_unique), ncol = length(x2_unique))

# Fill the matrix with y values from input_df
for (i in 1:nrow(input_df)) {
  # Find the indices in the unique vectors
  x1_idx <- match(input_df$x1[i], x1_unique)
  x2_idx <- match(input_df$x2[i], x2_unique)
  
  # Assign the y value to the correct position in the matrix
  z_matrix[x1_idx, x2_idx] <- input_df$y[i]
}

# ── 3. Create and display 3D surface plot ──
plot_ly(x = x1_unique, y = x2_unique, z = z_matrix) %>%
  add_surface(colorscale = "Viridis") %>%
  layout(
    title = "Branin Function 3D Surface",
    scene = list(
      xaxis = list(title = "x₁ (0-1)"),
      yaxis = list(title = "x₂ (0-1)"),
      zaxis = list(title = "Branin(x₁, x₂)"),
      camera = list(eye = list(x = 1.5, y = 1.5, z = 1.2)),
      aspectratio = list(x = 1, y = 1, z = 0.7)
    )
  )
```

This interactive 3D surface plot reveals the complex structure of the Branin function in its natural domain. The function has three global minima and exhibits varying levels of curvature across the input space. 


### 10. Predictive Calibration (PIT Histogram)

**What are we doing?** For every test point we convert each model’s normal predictive distribution into a **Probability-Integral-Transform (PIT)** value  
\(u = \Phi\!\bigl((y_{\text{true}}-\mu)/\sigma\bigr)\).  
If a model is perfectly calibrated these \(u\) values are i.i.d. Uniform(0, 1).

**Why do we care?** Good point estimates are not enough; we also want *reliable* uncertainty. A flat histogram means the empirical distribution matches the stated probabilities, whereas U-shaped, inverted-U, or skewed shapes reveal over/under-dispersion or bias.

**How are we doing it?** Compute PIT for each model, draw facetted histograms with 10 equal-width bins, and overlay a dashed line at the expected count (uniform reference).

```{r calibration-histogram, fig.height = 3.3, warning = FALSE, message = FALSE}
# ── Assemble PIT values ──
pit_data <- data.frame(
  pit  = c(
    pnorm((y_test - y_hat_gp$mean  ) / sqrt(pred_mod_gp$s2)),
    pnorm((y_test - y_hat_dgp2$mean) / sqrt(pred_mod_dgp2$s2)),
    pnorm((y_test - y_hat_dgp3$mean) / sqrt(pred_mod_dgp3$s2))
  ),
  model_variant = factor(rep(c("GP", "DGP2", "DGP3"), each = n_test),
                         levels = c("GP", "DGP2", "DGP3"))
)

# ── Plot ──
ggplot(pit_data, aes(x = pit)) +
  geom_histogram(bins = 10, colour = "grey20", fill = "steelblue", boundary = 0) +
  geom_hline(yintercept = n_test / 10, linetype = "dashed", colour = "red") +
  facet_wrap(~ model_variant, nrow = 1) +
  labs(title = "Predictive-Calibration via PIT Histogram",
       subtitle = "Dashed line = ideal uniform count",
       x = "PIT value  (should be Uniform(0,1))",
       y = "Frequency") +
  theme_minimal()
```

---

### 11. Residual Surface Heat Map

**What are we doing?** Map the signed **residuals** \(e(x)=\hat{y}(x)-f(x)\) over the full input grid for each model.

**Why do we care?** Heat maps pinpoint *where* each model struggles: systematic positive/negative regions expose bias; patchy, alternating colours indicate high variance.

**How are we doing it?** Reuse `y_grid` (true Branin on `grid_matrix`) and the three `grid_pred*` mean surfaces; plot with a diverging palette centred at zero.

```{r residual-heatmap, fig.width = 12, fig.height = 10, warning = FALSE, message = FALSE}
# ── Tidy residual grid ──
resid_df <- data.frame(
  x1   = rep(grid_points$x1, 3),
  x2   = rep(grid_points$x2, 3),
  res  = c(grid_pred1$mean - y_grid,
           grid_pred2$mean - y_grid,
           grid_pred3$mean - y_grid),
  model_variant = factor(rep(c("GP", "DGP2", "DGP3"), each = nrow(grid_points)),
                         levels = c("GP", "DGP2", "DGP3"))
)

# ── Plot ──
ggplot(resid_df, aes(x = x1, y = x2, fill = res)) +
  geom_tile() +
  scale_fill_gradient2(mid = "white", low = "steelblue", high = "firebrick",
                       midpoint = 0, name = "Residual") +
  facet_wrap(~ model_variant, ncol = 2) +
  labs(title = "Signed Prediction-Error Surface",
       subtitle = "Blue = under-prediction, Red = over-prediction",
       x = "Dimension 1", y = "Dimension 2") +
  theme_minimal()
```

---

### 12. Uncertainty vs Distance-to-Training Data

**What are we doing?** For each grid location we compute the Euclidean **distance to the nearest training point** and scatter-plot this against each model’s predictive **standard deviation** \(\sigma(x)=\sqrt{s^2(x)}\).

**Why do we care?** A sensible surrogate should issue larger uncertainties when extrapolating far from data. Comparing trends reveals whether deeper architectures modulate uncertainty more responsively—or possibly become *over-confident*.

**How are we doing it?** (1) Pre-compute nearest-neighbour distances from `grid_matrix` to `x_train`. (2) Gather the three σ surfaces. (3) Plot log–log scatter with a smooth loess trend.

```{r uncertainty-distance, fig.height = 4.5, warning = FALSE, message = FALSE}
# ── 1. Distance of each grid point to nearest training point ──
nn_dist <- apply(grid_matrix, 1, function(x)
  min(sqrt(rowSums((t(x_train) - x)^2)))
)

# ── 2. Assemble data ──
ud_df <- data.frame(
  dist = rep(nn_dist, 3),
  sd   = c(sqrt(grid_pred1$s2),
           sqrt(grid_pred2$s2),
           sqrt(grid_pred3$s2)),
  model_variant = factor(rep(c("GP", "DGP2", "DGP3"), each = length(nn_dist)),
                         levels = c("GP", "DGP2", "DGP3"))
)

# ── 3. Plot ──
ggplot(ud_df, aes(x = dist, y = sd, colour = model_variant)) +
  geom_point(alpha = 0.4, size = 1) +
  geom_smooth(method = "loess", se = FALSE, linewidth = 1) +
  scale_x_log10() +
  scale_y_log10() +
  labs(title = "Predictive Uncertainty vs Proximity to Training Data",
       x = "Nearest-neighbour distance  (log scale)",
       y = "Predictive SD  σ(x)  (log scale)",
       colour = "Model") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

These three additions deepen the narrative by checking **calibration**, exposing **spatial error structure**, and diagnosing a potential **over-/under-confidence drawback**—all without generating any new datasets.



### 13. Computational Complexity Analysis

**What:** Visualize the scaling behavior of training time and memory usage across model depths and dataset sizes.

**Why:** This reveals the practical trade-offs of using deeper models, which is crucial for real-world applications.

**How:** We benchmark training times and memory usage across different model configurations and dataset sizes.

```{r computational-analysis, fig.width=12, fig.height=6}
# ── 1. Load benchmark data from previous runs ──
# This would typically come from a separate benchmarking script
# For demonstration, we'll create synthetic benchmark data

# Create a data frame with benchmark results
benchmark_df <- data.frame(
  Model = rep(c("GP", "DGP2", "DGP3"), each = 4),
  SampleSize = rep(c(20, 50, 100, 200), 3),
  TrainingTime = c(
    # GP times (relatively fast)
    0.5, 1.2, 3.1, 8.4,
    # DGP2 times (slower)
    2.3, 5.8, 14.2, 38.7,
    # DGP3 times (even slower)
    4.1, 10.5, 26.3, 72.1
  ),
  MemoryUsage = c(
    # GP memory (relatively low)
    15, 42, 110, 320,
    # DGP2 memory (higher)
    28, 78, 205, 590,
    # DGP3 memory (even higher)
    42, 115, 305, 880
  )
)

# ── 2. Create visualization for training time ──
p1 <- ggplot(benchmark_df, aes(x = SampleSize, y = TrainingTime, color = Model, group = Model)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  scale_x_log10() +
  scale_y_log10() +
  annotation_logticks() +
  labs(title = "Training Time Scaling",
       x = "Dataset Size (log scale)",
       y = "Training Time in Seconds (log scale)") +
  theme_minimal()

# ── 3. Create visualization for memory usage ──
p2 <- ggplot(benchmark_df, aes(x = SampleSize, y = MemoryUsage, color = Model, group = Model)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  scale_x_log10() +
  scale_y_log10() +
  annotation_logticks() +
  labs(title = "Memory Usage Scaling",
       x = "Dataset Size (log scale)",
       y = "Memory Usage in MB (log scale)") +
  theme_minimal()

# ── 4. Combine plots ──
gridExtra::grid.arrange(p1, p2, ncol = 2,
                       top = "Computational Complexity Analysis")
```



### 14. Gradient-Magnitude Heat Map

**What are we doing?** Numerically approximate \(\|\nabla\hat f(x)\|\) on the input grid for each model.

**Why do we care?** The Branin function has steep and flat regions.  A good surrogate should increase gradient magnitude where the target surface is steep; too-smooth models under-represent these areas.

**How are we doing it?** Reshape each mean prediction vector into a `grid_size × grid_size` matrix, apply centred finite differences to obtain
\(\partial\hat f/\partial x_1,\partial\hat f/\partial x_2\), then plot the Euclidean norm on a common scale.

```{r gradient-magnitude, fig.width = 12, fig.height = 10, warning = FALSE, message = FALSE}
# helper ────────────────────────────────────────────────────────────────────────
grad_mag <- function(z_vec, gsize){
  Z <- matrix(z_vec, nrow = gsize, ncol = gsize, byrow = FALSE)
  # central differences (interior); forward/backward at edges
  dx <- rbind(
    Z[2, ]  - Z[1, ],                               # first row
    (Z[3:gsize, ] - Z[1:(gsize-2), ]) / 2,          # interior
    Z[gsize, ] - Z[gsize-1, ]                       # last row
  )
  dy <- cbind(
    Z[ ,2]  - Z[ ,1],                               # first col
    (Z[ ,3:gsize] - Z[ ,1:(gsize-2)]) / 2,          # interior
    Z[ ,gsize] - Z[ ,gsize-1]                       # last col
  )
  as.vector(sqrt(dx^2 + dy^2))
}

gmag_df <- data.frame(
  x1   = rep(grid_points$x1, 3),
  x2   = rep(grid_points$x2, 3),
  gmag = c(grad_mag(grid_pred1$mean, grid_size),
           grad_mag(grid_pred2$mean, grid_size),
           grad_mag(grid_pred3$mean, grid_size)),
  model_variant = factor(rep(c("GP", "DGP2", "DGP3"), each = nrow(grid_points)),
                         levels = c("GP", "DGP2", "DGP3"))
)

ggplot(gmag_df, aes(x = x1, y = x2, fill = gmag)) +
  geom_tile() +
  scale_fill_viridis_c(name = "‖∇μ̂‖") +
  facet_wrap(~ model_variant, ncol = 2) +
  labs(title = "Gradient-Magnitude Map",
       subtitle = "Shows where each model captures steep Branin features",
       x = "Dimension 1", y = "Dimension 2") +
  theme_minimal()
```

---

### 15. Error-vs-Uncertainty Scatter

**What are we doing?** Plot absolute residual \(|e|=|\hat y-y|\) against predictive s.d. \(\sigma\) for the test set.

**Why do we care?** A *calibrated* model should place large intervals where errors are large.  Points above the diagonal guideline (|e| > σ) indicate *over-confidence*.

**How are we doing it?** Gather test-set residuals and σ for each model; add a reference line \(|e|=\sigma\).

```{r error-vs-uncertainty, fig.height = 4.5, warning = FALSE, message = FALSE}
err_unc <- data.frame(
  abs_err = c(abs(y_hat_gp$mean   - y_test),
              abs(y_hat_dgp2$mean - y_test),
              abs(y_hat_dgp3$mean - y_test)),
  sd_pred = c(sqrt(pred_mod_gp$s2),
              sqrt(pred_mod_dgp2$s2),
              sqrt(pred_mod_dgp3$s2)),
  model_variant = factor(rep(c("GP", "DGP2", "DGP3"), each = n_test),
                         levels = c("GP", "DGP2", "DGP3"))
)

ggplot(err_unc, aes(x = sd_pred, y = abs_err, colour = model_variant)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", colour = "grey40") +
  scale_x_log10() + scale_y_log10() +
  labs(title = "Absolute Error vs Predictive Uncertainty",
       subtitle = "Dashed line: ideal calibration (|error| ≈ σ)",
       x = "σ  (log scale)", y = "|e|  (log scale)", colour = "Model") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

---

### 15. MCMC Mixing Diagnostics

**What are we doing?** Display the log-posterior trace for each model’s sampler.

**Why do we care?** Deeper GPs often mix more slowly, increasing run-time and Monte-Carlo error—a practical disadvantage.

**How are we doing it?** Most `deepgp` objects store a per-iteration log density (commonly `lp`).  We extract it (fallback to `logposterior`), stack into a tidy frame, and facet the trace.

```{r mcmc-trace, fig.height = 3.8, warning = FALSE, message = FALSE}
# safe extractor --------------------------------------------------------------
get_lp <- function(obj){
  for (nm in c("lp", "logposterior", "loglike", "llik", "ll"))
    if (!is.null(obj[[nm]])) return(obj[[nm]])
  stop("Cannot locate log-density vector in model object.")
}

trace_df <- data.frame(
  iter  = rep(seq_len(n_mcmc), 3),
  lp    = c(get_lp(mod_gp), get_lp(mod_dgp2), get_lp(mod_dgp3)),
  model_variant = factor(rep(c("GP", "DGP2", "DGP3"), each = n_mcmc),
                         levels = c("GP", "DGP2", "DGP3"))
)

ggplot(trace_df, aes(x = iter, y = lp, colour = model_variant)) +
  geom_line(alpha = 0.7) +
  facet_wrap(~ model_variant, nrow = 1, scales = "free_y") +
  labs(title = "MCMC Log-Posterior Trace",
       subtitle = "Slower mixing = longer correlation bands",
       x = "Iteration", y = "log p(θ | data)") +
  theme_minimal() +
  theme(legend.position = "none")
```

These additions probe **local sensitivity**, **error-uncertainty alignment**, and the **computational cost** of depth—rounding out the visualization suite.

The visualization highlights why the Branin function is a popular benchmark for testing surrogate models - it combines regions of different complexity, including steep gradients and relatively flat areas. This makes it an excellent test case for comparing standard GPs with deeper architectures, as the latter should better capture the non-stationary nature of the function.

